{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavanPrateek/GitDemo/blob/master/AcouosticModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV-7inMYPero",
        "outputId": "23e8c237-4669-40bb-b152-8e65a86316b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1).\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.6).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyAudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ydShN02Pxb8",
        "outputId": "7838b2b5-961d-4096-9dad-062cb53aab32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyAudio in /usr/local/lib/python3.7/dist-packages (0.2.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyparsing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IbGXhkANE2p",
        "outputId": "7f4a0e84-23b7-475f-9e87-9721b787b31c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (3.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pyaudio"
      ],
      "metadata": {
        "id": "uDNuTEgUPzEO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/utils')\n",
        "from utils import get_base_parser, update_parser, get_savepath\n",
        "from model_utils import check_and_download_models "
      ],
      "metadata": {
        "id": "HjjDeD-8P0mT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import getLogger   # noqa: E402\n",
        "logger = getLogger(__name__)"
      ],
      "metadata": {
        "id": "xxHSMzFuP5bj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MODEL_LISTS = [\n",
        "    'an4_pretrained_v2', 'librispeech_pretrained_v2', 'ted_pretrained_v2'\n",
        "]\n",
        "\n",
        "DEFAULT_MODEL = 'librispeech_pretrained_v2'\n",
        "\n",
        "WEIGHT_PATH = 'librispeech_pretrained_v2.onnx'\n",
        "MODEL_PATH = 'librispeech_pretrained_v2.onnx.prototxt'\n",
        "REMOTE_PATH = 'https://storage.googleapis.com/ailia-models/deepspeech2/'\n",
        "\n",
        "WAV_PATH = './1221-135766-0000.wav'\n",
        "SAVE_TEXT_PATH = 'output.txt'\n",
        "\n",
        "SAMPLING_RATE = 16000\n",
        "WIN_LENGTH = int(SAMPLING_RATE * 0.02)\n",
        "HOP_LENGTH = int(SAMPLING_RATE * 0.01)\n",
        "\n",
        "LABELS = list('_\\'ABCDEFGHIJKLMNOPQRSTUVWXYZ ')\n",
        "int_to_char = dict([(i, c) for (i, c) in enumerate(LABELS)])\n",
        "BRANK_LABEL_INDEX = 0\n",
        "\n",
        "# BeamCTCDecoder parameter\n",
        "LM_PATH = '3-gram.pruned.3e-7.arpa'\n",
        "ALPHA = 1.97\n",
        "BETA = 4.36\n",
        "CUTOFF_TOP_N = 40\n",
        "CUTOFF_PROB = 1.0\n",
        "NUM_PROCESS = 1\n",
        "BEAM_WIDTH = 128\n",
        "\n",
        "# pyaudio\n",
        "CHUNK = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "CHANNELS = 1\n",
        "RECODING_SAMPING_RATE = 48000\n",
        "THRESHOLD = 0.02"
      ],
      "metadata": {
        "id": "4UuIfUbWQW-M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parser = get_base_parser(\n",
        "    'deepspeech2', WAV_PATH, SAVE_TEXT_PATH, input_ftype='audio'\n",
        ")\n",
        "# overwrite\n",
        "parser.add_argument(\n",
        "    '-i', '--input', metavar='WAV',\n",
        "    default=WAV_PATH,\n",
        "    help='The input wav path.',\n",
        ")\n",
        "parser.add_argument(\n",
        "    '-V',\n",
        "    action='store_true',\n",
        "    help='use microphone input',\n",
        ")\n",
        "parser.add_argument(\n",
        "    '-d', '--beamdecode',\n",
        "    action='store_true',\n",
        "    help='use beam decoder',\n",
        ")\n",
        "parser.add_argument(\n",
        "    '-a', '--arch', metavar='WEIGHT',\n",
        "    default=DEFAULT_MODEL, choices=MODEL_LISTS,\n",
        "    help='model lists: ' + ' | '.join(MODEL_LISTS)\n",
        ")\n",
        "parser.add_argument(\n",
        "    '--ailia_audio', action='store_true',\n",
        "    help='use ailia audio library'\n",
        ")\n",
        "args = update_parser(parser)\n",
        "if args.ailia_audio:\n",
        "  import ailia.audio\n",
        "  import soundfile as sf\n",
        "else:\n",
        "  import librosa\n",
        "  import torch\n",
        "\n",
        "# ======================\n",
        "# Utils\n",
        "# ======================\n",
        "def create_spectrogram(wav):\n",
        "    if args.ailia_audio:\n",
        "        spectrogram = ailia.audio.create_spectrogram(\n",
        "            wav,\n",
        "            fft_n=WIN_LENGTH,\n",
        "            hop_n=HOP_LENGTH,\n",
        "            win_n=WIN_LENGTH,\n",
        "            win_type=\"hamming\",\n",
        "        )\n",
        "        spec_length = np.array(([spectrogram.shape[1]-1]))\n",
        "    else:\n",
        "        stft = librosa.stft(\n",
        "            wav,\n",
        "            n_fft=WIN_LENGTH,\n",
        "            win_length=WIN_LENGTH,\n",
        "            hop_length=HOP_LENGTH,\n",
        "            window='hamming',\n",
        "        )\n",
        "        stft, _ = librosa.magphase(stft)\n",
        "        spectrogram = np.log1p(stft)\n",
        "        spec_length = np.array(([stft.shape[1]-1]))\n",
        "\n",
        "        mean = spectrogram.mean()\n",
        "        std = spectrogram.std()\n",
        "        spectrogram -= mean\n",
        "        spectrogram /= std\n",
        "    \n",
        "    spectrogram = np.log1p(spectrogram)\n",
        "    spectrogram = spectrogram[np.newaxis, np.newaxis, :, :]\n",
        "\n",
        "    return (spectrogram, spec_length)\n",
        "\n",
        "\n",
        "def record_microphone_input():\n",
        "    logger.info('Ready...')\n",
        "    time.sleep(1)\n",
        "    p = pyaudio.PyAudio()\n",
        "\n",
        "    stream = p.open(\n",
        "        format=FORMAT,\n",
        "        channels=CHANNELS,\n",
        "        rate=RECODING_SAMPING_RATE,\n",
        "        input=True,\n",
        "        frames_per_buffer=CHUNK,\n",
        "    )\n",
        "\n",
        "    # time.sleep(1)\n",
        "    logger.info(\"Please speak something\")\n",
        "\n",
        "    frames = []\n",
        "    count_uv = 0\n",
        "\n",
        "    stream.start_stream()\n",
        "    while True:\n",
        "        data = np.frombuffer(stream.read(CHUNK), dtype=np.int16) / 32768.0\n",
        "        if data.max() > THRESHOLD:\n",
        "            frames.extend(data)\n",
        "            count_uv = 0\n",
        "        elif len(frames) > 0:\n",
        "            count_uv += 1\n",
        "            if count_uv > 48:\n",
        "                break\n",
        "            frames.extend(data)\n",
        "\n",
        "    # logger.info(\"Translating\")\n",
        "\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    p.terminate()\n",
        "\n",
        "    wav = np.array(frames)\n",
        "    if args.ailia_audio:\n",
        "        return ailia.audio.resample(wav, RECODING_SAMPING_RATE, SAMPLING_RATE)\n",
        "    else:\n",
        "        return librosa.resample(wav, RECODING_SAMPING_RATE, SAMPLING_RATE)\n",
        "\n",
        "\n",
        "def decode(sequence, size=None):\n",
        "    sequence = np.argmax(sequence, -1)\n",
        "\n",
        "    text = ''\n",
        "    size = int(size[0]) if size is not None else len(sequence)\n",
        "    for i in range(size):\n",
        "        char = int_to_char[sequence[i]]\n",
        "        if char != int_to_char[BRANK_LABEL_INDEX]:\n",
        "            if i != 0 and char == int_to_char[sequence[i - 1]]:\n",
        "                pass\n",
        "            else:\n",
        "                text += char\n",
        "    return text.lower()\n",
        "\n",
        "\n",
        "def beam_ctc_decode(sequence, size=None, decoder=None):\n",
        "    \"\"\"\n",
        "    Decode using language model\n",
        "    \"\"\"\n",
        "    out, scores, offsets, seq_len = decoder.decode(sequence, size)\n",
        "\n",
        "    # results = []\n",
        "    for b, batch in enumerate(out):\n",
        "        utterances = []\n",
        "        for p, utt in enumerate(batch):\n",
        "            size = seq_len[0][p]\n",
        "            if size > 0:\n",
        "                transcript = ''.join(\n",
        "                    map(lambda x: int_to_char[x.item()], utt[0:size])\n",
        "                )\n",
        "            else:\n",
        "                transcript = ''\n",
        "        utterances.append(transcript)\n",
        "\n",
        "    return utterances[0].lower()\n",
        "\n",
        "\n",
        "# ======================\n",
        "# Main functions\n",
        "# ======================\n",
        "def wavfile_input_recognition():\n",
        "    if args.beamdecode:\n",
        "        try:\n",
        "            from ctcdecode import CTCBeamDecoder\n",
        "        except ImportError:\n",
        "            raise ImportError(\"BeamCTCDecoder requires paddledecoder package.\")\n",
        "\n",
        "        decoder = CTCBeamDecoder(\n",
        "            LABELS,\n",
        "            LM_PATH,\n",
        "            ALPHA,\n",
        "            BETA,\n",
        "            CUTOFF_TOP_N,\n",
        "            CUTOFF_PROB,\n",
        "            BEAM_WIDTH,\n",
        "            NUM_PROCESS,\n",
        "            BRANK_LABEL_INDEX,\n",
        "        )\n",
        "\n",
        "    # net initialize\n",
        "    net = ailia.Net(MODEL_PATH, WEIGHT_PATH, env_id=args.env_id)\n",
        "\n",
        "    for soundf_path in args.input:\n",
        "        logger.info(soundf_path)\n",
        "        if args.ailia_audio:\n",
        "            wav,sr = sf.read(soundf_path)\n",
        "            wav = ailia.audio.resample(wav,sr,SAMPLING_RATE)\n",
        "        else:\n",
        "            wav = librosa.load(soundf_path, sr=SAMPLING_RATE)[0]\n",
        "        spectrogram = create_spectrogram(wav)\n",
        "        net.set_input_shape(spectrogram[0].shape)\n",
        "\n",
        "        # inference\n",
        "        logger.info('Start inference...')\n",
        "        if args.benchmark:\n",
        "            logger.info('BENCHMARK mode')\n",
        "            for c in range(5):\n",
        "                start = int(round(time.time() * 1000))\n",
        "                preds_ailia, output_length = net.predict(spectrogram)\n",
        "                end = int(round(time.time() * 1000))\n",
        "                logger.info(\"\\tailia processing time {} ms\".format(end-start))\n",
        "        else:\n",
        "            # Deep Speech output: output_probability, output_length\n",
        "            preds_ailia, output_length = net.predict(spectrogram)\n",
        "\n",
        "        if args.beamdecode:\n",
        "            text = beam_ctc_decode(\n",
        "                torch.from_numpy(preds_ailia),\n",
        "                torch.from_numpy(output_length),\n",
        "                decoder,\n",
        "            )\n",
        "        else:\n",
        "            text = decode(preds_ailia[0], output_length)\n",
        "\n",
        "        savepath = get_savepath(args.savepath, soundf_path, ext='.txt')\n",
        "        logger.info(f'Results saved at : {savepath}')\n",
        "        with open(savepath, 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "        logger.info(f'predict sentence:\\n{text}')\n",
        "    logger.info('Script finished successfully.')\n",
        "\n",
        "\n",
        "# ======================\n",
        "# microphone input mode\n",
        "# ======================\n",
        "def microphone_input_recognition():\n",
        "    if args.beamdecode:\n",
        "        try:\n",
        "            from ctcdecode import CTCBeamDecoder\n",
        "        except ImportError:\n",
        "            raise ImportError(\"BeamCTCDecoder requires paddledecoder package.\")\n",
        "\n",
        "        decoder = CTCBeamDecoder(\n",
        "            LABELS,\n",
        "            LM_PATH,\n",
        "            ALPHA,\n",
        "            BETA,\n",
        "            CUTOFF_TOP_N,\n",
        "            CUTOFF_PROB,\n",
        "            BEAM_WIDTH,\n",
        "            NUM_PROCESS,\n",
        "            BRANK_LABEL_INDEX,\n",
        "        )\n",
        "\n",
        "    while True:\n",
        "        wav = record_microphone_input()\n",
        "        spectrogram = create_spectrogram(wav)\n",
        "\n",
        "        # net initialize\n",
        "        net = ailia.Net(MODEL_PATH, WEIGHT_PATH, env_id=args.env_id)\n",
        "        net.set_input_shape(spectrogram[0].shape)\n",
        "\n",
        "        # inference\n",
        "        logger.info('Translating...')\n",
        "        # Deep Speech output: output_probability, output_length\n",
        "        preds_ailia, output_length = net.predict(spectrogram)\n",
        "\n",
        "        if args.beamdecode:\n",
        "            text = beam_ctc_decode(\n",
        "                torch.from_numpy(preds_ailia),\n",
        "                torch.from_numpy(output_length),\n",
        "                decoder,\n",
        "            )\n",
        "        else:\n",
        "            text = decode(preds_ailia[0], output_length)\n",
        "\n",
        "        logger.info(f'predict sentence:\\n{text}\\n')\n",
        "        time.sleep(1)\n",
        "\n",
        "\n",
        "def main():\n",
        "    global WEIGHT_PATH, MODEL_PATH\n",
        "    if args.arch != WEIGHT_PATH:\n",
        "        WEIGHT_PATH = args.arch + '.onnx'\n",
        "        MODEL_PATH = WEIGHT_PATH + '.prototxt'\n",
        "\n",
        "    check_and_download_models(WEIGHT_PATH, MODEL_PATH, REMOTE_PATH)\n",
        "    check_and_download_models(LM_PATH, LM_PATH, REMOTE_PATH)\n",
        "\n",
        "    # microphone input mode\n",
        "    if args.V:\n",
        "        try:\n",
        "            microphone_input_recognition()\n",
        "        except KeyboardInterrupt:\n",
        "            logger.info('script finished successfully.')\n",
        "\n",
        "    # sound file input mode\n",
        "    else:\n",
        "        wavfile_input_recognition()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "VEmHfTsXQYmZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "c5816081-ca12-4a23-8ba6-f1cbbf65ca66"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-v VIDEO] [-s SAVE_PATH] [-b] [-e ENV_ID]\n",
            "                             [--env_list] [--ftype FILE_TYPE] [--debug]\n",
            "                             [--profile] [-bc BENCHMARK_COUNT] [-i WAV] [-V]\n",
            "                             [-d] [-a WEIGHT] [--ailia_audio]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-455fff81-dad9-4111-a10e-4b7bf9793a6e.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tb"
      ],
      "metadata": {
        "id": "G1vHKABUQaIZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "outputId": "c3a3062a-11e3-487f-c3c4-7b6617c4ea8c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-fd0912d67bdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'use ailia audio library'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mailia_audio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mailia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils/utils.py\u001b[0m in \u001b[0;36mupdate_parser\u001b[0;34m(parser, check_input_type, large_model)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdone\u001b[0m \u001b[0mhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2515\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2517\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Oh4mF__0SYh0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}